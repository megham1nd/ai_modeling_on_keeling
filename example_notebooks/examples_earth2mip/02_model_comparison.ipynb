{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Basic Inference with Multiple Models\n",
        "\n",
        "The following notebook demonstrates how to use Earth-2 MIP for running different AI\n",
        "weather models and comparing their outputs. Specifically, this will compare the Pangu\n",
        "weather model and Deep Learning Weather Prediction (DLWP) mode with an intial state\n",
        "pulled from the Climate Data Store (CDS). This will also how how to interact with\n",
        "Earth-2 MIP using Python APIs for greater control over inference workflows.\n",
        "\n",
        "In summary this notebook will cover the following topics:\n",
        "\n",
        "- Configuring and setting up Pangu Model Registry and DLWP Model Registry\n",
        "- Setting up a basic deterministic inferencer for both models\n",
        "- Running inference in a Python script\n",
        "- Post processing results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Up\n",
        "Starting off with imports, hopefully you have already installed Earth-2 MIP from this\n",
        "repository. See the previous notebook for information about configuring Earth-2 MIP, its\n",
        "assumed enviroment variables have already been properly set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'custom_fwd' from 'torch.amp' (/data/keeling/a/megha4/miniconda3/envs/earth2mip_env/lib/python3.10/site-packages/torch/amp/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\n\u001b[1;32m      9\u001b[0m dotenv\u001b[38;5;241m.\u001b[39mload_dotenv()\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mearth2mip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inference_ensemble, registry\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mearth2mip\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitial_conditions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cds\n",
            "File \u001b[0;32m~/miniconda3/envs/earth2mip_env/lib/python3.10/site-packages/earth2mip/inference_ensemble.py:42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mearth2mip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initial_conditions, regrid, time_loop\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mearth2mip\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_channel_stds\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m channel_stds\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mearth2mip\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     43\u001b[0m     generate_bred_vector,\n\u001b[1;32m     44\u001b[0m     generate_noise_correlated,\n\u001b[1;32m     45\u001b[0m     generate_noise_grf,\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mearth2mip\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetcdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initialize_netcdf, update_netcdf\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mearth2mip\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetworks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_model\n",
            "File \u001b[0;32m~/miniconda3/envs/earth2mip_env/lib/python3.10/site-packages/earth2mip/ensemble_utils.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Union\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_harmonics\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mth\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mearth2mip\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtime_loop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeLoop\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGaussianRandomFieldS2\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n",
            "File \u001b[0;32m~/miniconda3/envs/earth2mip_env/lib/python3.10/site-packages/torch_harmonics/__init__.py:35\u001b[0m\n\u001b[1;32m     32\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.7.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msht\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RealSHT, InverseRealSHT, RealVectorSHT, InverseRealVectorSHT\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvolution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiscreteContinuousConvS2, DiscreteContinuousConvTransposeS2\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quadrature\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random_fields\n",
            "File \u001b[0;32m~/miniconda3/envs/earth2mip_env/lib/python3.10/site-packages/torch_harmonics/convolution.py:44\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_harmonics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquadrature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _precompute_grid, _precompute_latitudes\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_harmonics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_disco_convolution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _disco_s2_contraction_torch, _disco_s2_transpose_contraction_torch\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_harmonics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_disco_convolution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _disco_s2_contraction_cuda, _disco_s2_transpose_contraction_cuda\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# import custom C++/CUDA extensions\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/earth2mip_env/lib/python3.10/site-packages/torch_harmonics/_disco_convolution.py:35\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m custom_fwd, custom_bwd\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdisco_cuda_extension\u001b[39;00m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'custom_fwd' from 'torch.amp' (/data/keeling/a/megha4/miniconda3/envs/earth2mip_env/lib/python3.10/site-packages/torch/amp/__init__.py)"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import os\n",
        "import torch\n",
        "\n",
        "import dotenv\n",
        "import xarray\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "from earth2mip import inference_ensemble, registry\n",
        "from earth2mip.initial_conditions import cds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The cell above created a model registry folder for us, now we need to populate it with\n",
        "model packages.\n",
        "We will start with Pangu, which is a model that uses ONNX checkpoints.\n",
        "Since this is a built in model, we can use the `registry.get_model` function with the\n",
        "`e2mip://` prefix to auto download the checkpoints.\n",
        "Under the hood, this is fetching the ONNX checkpoints and creating a `metadata.json`\n",
        "file to help Earth-2 MIP know how to load the model into memory for inference.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Fetching Pangu model package...\")\n",
        "package = registry.get_model(\"e2mip://pangu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next DLWP model package will need to be downloaded. This model follows the standard\n",
        "proceedure most do in Earth-2 MIP, being served via Modulus and hosted on NGC model\n",
        "registry.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Fetching DLWP model package...\")\n",
        "package = registry.get_model(\"e2mip://dlwp\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The final setup step is to set up your CDS API key so we can access ERA5 data to act as\n",
        "an initial state. Earth-2 MIP supports a number of different initial state data sources\n",
        "that are supported including HDF5, CDS, GFS, etc. The CDS initial state provides a\n",
        "convenient way to access a limited amount of historical weather data. Its recommended\n",
        "for accessing an initial state, but larger data requirements should use locally stored\n",
        "weather datasets.\n",
        "\n",
        "Enter your CDS API uid and key below (found under your profile page).\n",
        "If you don't a CDS API key, find out more here.\n",
        "\n",
        "- [https://cds.climate.copernicus.eu/cdsapp#!/home](https://cds.climate.copernicus.eu/cdsapp#!/home)\n",
        "- [https://cds.climate.copernicus.eu/api-how-to](https://cds.climate.copernicus.eu/api-how-to)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cds_api = os.path.join(os.path.expanduser(\"~\"), \".cdsapirc\")\n",
        "if not os.path.exists(cds_api):\n",
        "    uid = input(\"Enter in CDS UID (e.g. 123456): \")\n",
        "    key = input(\"Enter your CDS API key (e.g. 12345678-1234-1234-1234-123456123456): \")\n",
        "    # Write to config file for CDS library\n",
        "    with open(cds_api, \"w\") as f:\n",
        "        f.write(\"url: https://cds.climate.copernicus.eu/api/v2\\n\")\n",
        "        f.write(f\"key: {uid}:{key}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running Inference\n",
        "To run inference of these models we will use some of Earth-2 MIPs Python APIs to perform\n",
        "inference. The first step is to load the model from the model registry, which is done\n",
        "using the `registry.get_model` command. This will look in your `MODEL_REGISTRY` folder\n",
        "for the provided name and use this as a filesystem for loading necessary files.\n",
        "\n",
        "The model is then loaded into memory using the load function for that particular\n",
        "network. Earth-2 MIP has multiple abstracts that can allow this to be automated that can\n",
        "be used instead if desired.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import earth2mip.networks.dlwp as dlwp\n",
        "import earth2mip.networks.pangu as pangu\n",
        "\n",
        "# Output directoy\n",
        "output_dir = \"outputs/02_model_comparison\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"Loading models into memory\")\n",
        "# Load DLWP model from registry\n",
        "package = registry.get_model(\"dlwp\")\n",
        "dlwp_inference_model = dlwp.load(package)\n",
        "\n",
        "# Load Pangu model(s) from registry\n",
        "package = registry.get_model(\"pangu\")\n",
        "pangu_inference_model = pangu.load(package)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we set up the initial state data source for January 1st, 2018 at 00:00:00 UTC.\n",
        "As previously mentioned, we will pull data on the fly from CDS (make sure you set up\n",
        "your API key above). Since DLWP and Pangu require different channels (and time steps),\n",
        "we will create two seperate data-sources for them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "time = datetime.datetime(2018, 1, 1)\n",
        "\n",
        "# DLWP datasource\n",
        "dlwp_data_source = cds.DataSource(dlwp_inference_model.in_channel_names)\n",
        "\n",
        "# Pangu datasource, this is much simplier since pangu only uses one timestep as an input\n",
        "pangu_data_source = cds.DataSource(pangu_inference_model.in_channel_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the initial state downloaded for each and set up in an Xarray dataset, we can now\n",
        "run deterministic inference for both which can be achieved using the\n",
        "`inference_ensemble.run_basic_inference` method which will produce a Xarray\n",
        "[data array](https://docs.xarray.dev/en/stable/generated/xarray.DataArray.html) to then\n",
        "work with.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Running Pangu inference\")\n",
        "pangu_ds = inference_ensemble.run_basic_inference(\n",
        "    pangu_inference_model,\n",
        "    n=24,  # Note we run 24 steps here because Pangu is at 6 hour dt (6 day forecast)\n",
        "    data_source=pangu_data_source,\n",
        "    time=time,\n",
        ")\n",
        "pangu_ds.to_netcdf(f\"{output_dir}/pangu_inference_out.nc\")\n",
        "print(pangu_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Running DLWP inference\")\n",
        "dlwp_ds = inference_ensemble.run_basic_inference(\n",
        "    dlwp_inference_model,\n",
        "    n=24,  # Note we run 24 steps. DLWP steps at 12 hr dt, but yeilds output every 6 hrs (6 day forecast)\n",
        "    data_source=dlwp_data_source,\n",
        "    time=time,\n",
        ")\n",
        "dlwp_ds.to_netcdf(f\"{output_dir}/dlwp_inference_out.nc\")\n",
        "print(dlwp_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Post Processing\n",
        "With inference complete, now the fun part: post processing and analysis!\n",
        "Here we will just plot the z500 (geopotential at pressure level 500) contour time-series of both models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Open dataset from saved NetCDFs\n",
        "pangu_ds = xarray.open_dataarray(f\"{output_dir}/pangu_inference_out.nc\")\n",
        "dlwp_ds = xarray.open_dataarray(f\"{output_dir}/dlwp_inference_out.nc\")\n",
        "\n",
        "# Get data-arrays at 12 hour steps\n",
        "pangu_arr = pangu_ds.sel(channel=\"z500\").values[::2]\n",
        "dlwp_arr = dlwp_ds.sel(channel=\"z500\").values[::2]\n",
        "# Plot\n",
        "plt.close(\"all\")\n",
        "fig, axs = plt.subplots(2, 13, figsize=(13 * 4, 5))\n",
        "for i in range(13):\n",
        "    axs[0, i].imshow(dlwp_arr[i, 0])\n",
        "    axs[1, i].imshow(pangu_arr[i, 0])\n",
        "    axs[0, i].set_title(time + datetime.timedelta(hours=12 * i))\n",
        "\n",
        "axs[0, 0].set_ylabel(\"DLWP\")\n",
        "axs[1, 0].set_ylabel(\"Pangu\")\n",
        "plt.suptitle(\"z500 DLWP vs Pangu\")\n",
        "plt.savefig(f\"{output_dir}/pangu_dlwp_z500.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And that completes the second notebook detailing how to run deterministic inference of\n",
        "two models using Earth-2 MIP. In the next notebook, we will look at how to score a\n",
        "model compared against ERA5 re-analysis data.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
